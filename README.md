# GPT200

**The Smallest GPT Implementation**
_(200 lines)_

A minimalist yet fully-functional GPT for educational purposes.

Perfect for learning transformer architectures without drowning in frameworks.

## ✨ Features

- **Train + Inference** in <200 lines of core logic
- Interactive demos for text generation

## ⚡ Quick Start

```bash
git clone https://github.com/
```
